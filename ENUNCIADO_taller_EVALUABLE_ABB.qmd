---
title: "ENUNCIADO taller en grupo Mat3 GIN 2025-2026"
author: "Taller"
lang: es
format:
  html:
    theme: superhero
    toc: true
    toc_depth: 4
    html-math-method: katex
    code-tools: true
    code-fold: true
    collapse: true
    keep-md: true
    code-overflow: wrap
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE,cache=FALSE)
# packages
library(tidyverse)
library(kableExtra)
```

# Instrucciones para el taller

Se entrega en grupos que deben de estar constituidos en la actividad de grupos. Los grupos son de 2 o 3 ESTUDIANTES, loa caso especiales consultadlos con el profesor para que los autorice.

**Enlaces y Bibliografía**

-   [R for data science, Hadley Wickham, Garret Grolemund.](https://r4ds.had.co.nz/)
-   [Fundamentos de ciencia de datos con R.](https://cdr-book.github.io/)
-   [Tablas avanzadas: kable, KableExtra.](https://haozhu233.github.io/kableExtra/awesome_table_in_html.html)
-   [Geocomputation with R, Robin Lovelace, Jakub Nowosad, Jannes Muenchow](https://r.geocompx.org/)
-   Apuntes de R-basico y tidyverse moodel MAT3.

## Objetivo MALLORCA

Leeremos los siguientes datos de la zona de etiqueta `mallorca` con el código siguiente:

```{r}
load("clean_data/mallorca/listing_common0.RData")
ls()
listings0 = listings_common0 %>%
  select(id, scrape_id, listing_url,
         neighbourhood_cleansed, price,
         number_of_reviews,
         review_scores_rating,
         review_scores_rating,
         review_scores_cleanliness,
         review_scores_location,
         review_scores_value,
         number_of_reviews,
         accommodates,
         bathrooms_text,
         bedrooms,
         beds,
         minimum_nights,
         description,
         latitude,
         longitude,
         property_type,
         room_type)
```


**listings**

Generamos la  tibble `listings0` con datos DE  8 periodos  DE  apartamentos de inside Airbnb de Mallorca Y  seleccionando cuantas variables nos parecen más interesantes.

Separararemos la fecha del scrapping que es en la que se observaron  los datos de cada apartamento  nos quedaremos con los apartamentos que aparecen en las 8 periodos "scrapeados".

```{r}
listings0= listings0 %>% 
  mutate(date=as.Date(substr(
    as.character(scrape_id),1,8),
    format="%Y%m%d"),
    .after=id)
```

Ahora  analizamos  las fechas de los scrapings y el número de veces que aparecen 
 cada  apartamentos.



```{r}
table(listings0$date)
```
Hay 8 periodos de scrapping y vamos a quedarnos con los apartamentos que aparecen en todos los periodos


Vemos que cada apartamento aparece 8 veces una por periodo.


```{r}
table(table(listings0$id))
```


Notemos que cada apartamento:

-   queda identificado por id y por date que nos da el periodo en la que apareció el dato.
-   así que cada apartamento aparece 8 veces ya que hemos elegido solo los apartamentos que aparecen en las 8 muestras.
-   Las muestras son `r unique(listings0$date)`,

```{r}
unique(listings0$date)
```

**reviews**

Estos datos necesitan leerse de forma adecuada, las columnas 1, 2 y 4 deben ser de tipo `character` las otras son correctas

```{r}
reviews=read_csv("data/mallorca/2025-09-21/reviews.csv.gz")
str(reviews)
head(reviews)
```

**neighbourhoods.csv**

Son dos columnas y la primera es una agrupación de municipios (están NA) y la segunda es el nombre del municipio

```{r}
municipios=read_csv("data/mallorca/2025-09-21/neighbourhoods.csv")
str(municipios)
head(municipios)
```

**neighbourhoods.geojson**

Es el mapa de Mallorca, o podemos leer así:

```{r}
library(sf)
library(tmap)

# Leer el archivo GeoJSON
geojson_sf <- sf::st_read("data/mallorca/2025-09-21/neighbourhoods.geojson")

# Crear un mapa

# interactivo
tmap_mode("plot") # Cambiar a modo  view/plot   que es interactivo/estático
tm_shape(geojson_sf) +
  tm_polygons(col = "cyan", alpha = 0.6) +
  tm_layout(title = "Mapa - GeoJSON Mallorca con municipios")
```

Tenéis que consultar en la documentación de inside Airbnb para saber que significa cada variable. Os puede ser útil leer los ficheros [DATA_ABB_modelo_de_datos.html](DATA_ABB_modelo_de_datos.html) y [DATA_ABB_modelo_de_datos.pdf](DATA_ABB_modelo_de_datos.html) en los que se explica el modelo de datos de inside Airbnb y como se cargan en el espacio de trabajo.

Responder las siguientes preguntas con formato Rmarkdown (.Rmd) o quarto (.qmd) y entregad la fuente un fichero en formato html como salida del informe. Se puntúa la claridad de la respuesta, la calidad de la redacción y la corrección de la respuesta.

## Pregunta 1 (**1punto**)

Del fichero con los datos de listings `listings0` calcula los estadísticos descriptivos de las variable `price` y de la variable `number_of_reviews` agrupados por municipio y por periodo.

Presenta los resultados con una tabla de kableExtra.

```{r preg1, message=TRUE, warning=TRUE}
# ---------------------------------------------------------------
# PREGUNTA 1
# Estadísticos descriptivos de:
#   - price
#   - number_of_reviews
# agrupados por:
#   - municipio (neighbourhood_cleansed)
#   - periodo (date)
# Tabla de salida con kableExtra
# ---------------------------------------------------------------

# IMPORTANTE:
# Aquí asumimos que:
#  - listings0 ya está creado según el enunciado
#  - listings0 tiene la columna 'date'
#  - 'price' es numérica (si no lo es, habría que convertirla en otro chunk)
library(dplyr)
library(kableExtra)

# 1. Calcular los estadísticos descriptivos por municipio y periodo.
#    group_by(): forma grupos por municipio y fecha de scraping
#    summarise(): calcula los resúmenes para cada grupo
resumen_p1 <- listings0 %>%
  group_by(neighbourhood_cleansed, date) %>%
  summarise(
    # Tamaño de muestra en cada grupo
    n = n(),
    
    # ---- Estadísticos para 'price' ----
    mean_price = mean(price, na.rm = TRUE),              # media
    sd_price   = sd(price, na.rm = TRUE),                # desviación estándar
    min_price  = min(price, na.rm = TRUE),               # mínimo
    q1_price   = quantile(price, 0.25, na.rm = TRUE),    # cuartil 1
    med_price  = median(price, na.rm = TRUE),            # mediana
    q3_price   = quantile(price, 0.75, na.rm = TRUE),    # cuartil 3
    max_price  = max(price, na.rm = TRUE),               # máximo
    
    # ---- Estadísticos para 'number_of_reviews' ----
    mean_reviews = mean(number_of_reviews, na.rm = TRUE),   # media
    sd_reviews   = sd(number_of_reviews, na.rm = TRUE),     # desviación estándar
    med_reviews  = median(number_of_reviews, na.rm = TRUE), # mediana
    
    # Indicar a dplyr que "desagrupe" al terminar
    .groups = "drop"
  )

# (Opcional) ver una muestra de la tabla en la consola
# head(resumen_p1)

# 2. Ordenar y mostrar la tabla con kableExtra


# Opcional: que los NA aparezcan como vacío en la tabla
options(knitr.kable.NA = "")

tabla_p1 <- resumen_p1 %>%
  arrange(neighbourhood_cleansed, date) %>%              # ordenar municipio/fecha
  mutate(across(where(is.numeric), ~ round(., 2)))       # redondear numéricos

# Necesitas saber el número de filas para colorear el cuerpo
n_filas <- nrow(tabla_p1) 

tabla_p1 %>%
  kbl(
    caption = "Estadísticos descriptivos de price y number_of_reviews por municipio y periodo",
    col.names = c(
      "Municipio", "Periodo", "n",
      "Media", "SD", "Mín.", "Q1", "Mediana", "Q3", "Máx.",
      "Media", "SD", "Mediana"
    ),
    align    = c("l", "c", "r", rep("r", 10)),
    booktabs = TRUE
  ) %>%
  add_header_above(c(" " = 3, "Price" = 7, "Number of reviews" = 3),background = "#2c3e50") %>%
  kable_styling(
    full_width        = FALSE,
    # Nota: Si pones un color de fondo manual, a veces es mejor quitar "striped"
    # para que no se mezcle, pero puedes dejarlo si quieres.
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  ) %>%
  column_spec(1, bold = TRUE) %>%
  
  # --- AQUÍ ESTÁ EL CAMBIO DE COLOR ---
  
  # 1. Cambiar color de fondo de la CABECERA (Fila 0)
  # 'color' es el texto, 'background' es el fondo
  row_spec(0, bold = TRUE, color = "white", background = "#2c3e50") %>% 
  
  # 2. Cambiar color de fondo de las FILAS DE DATOS (Filas 1 hasta n)
  # Esto quitará el blanco de fondo. Puedes usar nombres ("lightyellow") o Hex ("#fffff0")
  row_spec(1:n_filas, color = "white", background = "#2c3e50") %>% 
  
  # -------------------------------------
  
  collapse_rows(columns = 1, valign = "top") %>%
  scroll_box(width="100%", height="600px")

```


## Pregunta 2 (**1punto**)

Consideremos las variables `price` y `number_of_reviews` de Pollença y Palma del periodo "2024-09-13", del fichero `listing_common0_select.RData`. 
Estudiad si estos datos se aproximan a una distribución normal gráficamente. Para ello, dibujad el histograma, la función "kernel-density" que aproxima la densidad y la densidad de la normal de media y varianza las de las muestras de las variables `price` (para precios mayores de 50 y menores de 400) y `number_of_reviews` para Palma y Pollença

```{r pregunta2, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

# -------------------------------------------------------------------
# Supongo que ya tienes 'listings0' creado con la columna 'date'.
# Si lo cargas de otro fichero (p.ej. listing_common0_select.RData),
# simplemente asegúrate de que se llama 'listings0' y tiene:
#   - date
#   - neighbourhood_cleansed
#   - price
#   - number_of_reviews
# -------------------------------------------------------------------

# 1) Filtrar solo la fecha y los municipios de interés
datos_2 <- listings0 %>%
  filter(
    date == as.Date("2024-09-13"),
    neighbourhood_cleansed %in% c("Pollença", "Palma de Mallorca")
  )

# 2) Para PRICE solo queremos precios entre 50 y 400 €
datos_price <- datos_2 %>%
  filter(price > 50, price < 400)

# ----------------- FUNCIONES AUXILIARES DE GRÁFICO -----------------

# Histograma + densidad kernel + curva normal (misma media y sd) para PRICE
grafico_price <- function(df, titulo) {
  m <- mean(df$price, na.rm = TRUE)
  s <- sd(df$price, na.rm = TRUE)
  
  # Secuencia de x y densidad normal teórica
  x_seq <- seq(
    from = min(df$price, na.rm = TRUE),
    to   = max(df$price, na.rm = TRUE),
    length.out = 400
  )
  normal_df <- data.frame(
    x    = x_seq,
    dens = dnorm(x_seq, mean = m, sd = s)
  )
  
  ggplot(df, aes(x = price)) +
    geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.4) +
    geom_density(linewidth = 1) +
    geom_line(data = normal_df, aes(x = x, y = dens),
              linewidth = 1, linetype = "dashed") +
    labs(
      title = titulo,
      x = "Precio por noche (€)",
      y = "Densidad"
    ) +
    theme_minimal()
}

# Histograma + densidad kernel + curva normal para NUMBER_OF_REVIEWS
grafico_reviews <- function(df, titulo) {
  m <- mean(df$number_of_reviews, na.rm = TRUE)
  s <- sd(df$number_of_reviews,   na.rm = TRUE)
  
  x_seq <- seq(
    from = min(df$number_of_reviews, na.rm = TRUE),
    to   = max(df$number_of_reviews, na.rm = TRUE),
    length.out = 400
  )
  normal_df <- data.frame(
    x    = x_seq,
    dens = dnorm(x_seq, mean = m, sd = s)
  )
  
  ggplot(df, aes(x = number_of_reviews)) +
    geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.4) +
    geom_density(linewidth = 1) +
    geom_line(data = normal_df, aes(x = x, y = dens),
              linewidth = 1, linetype = "dashed") +
    labs(
      title = titulo,
      x = "Número de reviews",
      y = "Densidad"
    ) +
    theme_minimal()
}

# ----------------- SEPARAR DATOS POR MUNICIPIO -----------------

# Palma de Mallorca
palma_price <- datos_price %>%
  filter(neighbourhood_cleansed == "Palma de Mallorca")
palma_rev <- datos_2 %>%
  filter(neighbourhood_cleansed == "Palma de Mallorca")

# Pollença
pollenca_price <- datos_price %>%
  filter(neighbourhood_cleansed == "Pollença")
pollenca_rev <- datos_2 %>%
  filter(neighbourhood_cleansed == "Pollença")

# ----------------- GRÁFICOS A MOSTRAR EN EL INFORME -----------------

# 1) PRICE (50–400 €) Palma
grafico_price(
  palma_price,
  "Palma de Mallorca – price (50–400 €), 2024-09-13"
)

# 2) PRICE (50–400 €) Pollença
grafico_price(
  pollenca_price,
  "Pollença – price (50–400 €), 2024-09-13"
)

# 3) NUMBER_OF_REVIEWS Palma
grafico_reviews(
  palma_rev,
  "Palma de Mallorca – number_of_reviews, 2024-09-13"
)

# 4) NUMBER_OF_REVIEWS Pollença
grafico_reviews(
  pollenca_rev,
  "Pollença – number_of_reviews, 2024-09-13"
)
```

## Pregunta 3 (**1punto**)

Con los datos de `listings0` de todos los periodos, contrastar si la media del precio en Alcudia es igual a la de Palma **contra** que es mayor que en Palma para los precios mayores que 50 euros y menores de 400. Construid la hipótesis nula y alternativa, calculad el $p$-valor y el intervalo de confianza asociado al contraste. Justifica técnicamente la conclusión del contraste.

```{r}
# 1. Filtrar los datos:
#    - Seleccionamos solo los registros con precio > 50 y < 400
#    - Seleccionamos los municipios "Alcúdia" y "Palma de Mallorca"
datos_p3 <- listings0 %>%
  filter(price > 50 & price < 400) %>%
  filter(neighbourhood_cleansed %in% c("Alcúdia", "Palma de Mallorca"))

# 2. Separar en dos vectores para facilitar el t.test
# Nota: Asegurarse de cómo está escrito el nombre en los datos (con o sin acento). 
# En los datos oficiales suele ser "Alcúdia".
precios_alcudia <- datos_p3 %>%
  filter(neighbourhood_cleansed == "Alcúdia") %>%
  pull(price)

precios_palma <- datos_p3 %>%
  filter(neighbourhood_cleansed == "Palma de Mallorca") %>%
  pull(price)

# 3. Realizar el t-test
#    alternative = "greater" porque queremos probar si Alcúdia > Palma
test_p3 <- t.test(x = precios_alcudia, 
                  y = precios_palma, 
                  alternative = "greater", 
                  var.equal = FALSE) # Asumimos varianzas desiguales (Welch)

# Mostramos el resultado
test_p3
```



## Pregunta 4 (**1punto**)

Con los  datos de `listings0`, contrastar si las medias de los precios en Alcudia entre los periodos  2025-06-15 y   2025-09-21 son iguales contra que son menores en 2023. Construid la hipótesis nula y alternativa, calculad el $p$-valor y el intervalo de confianza asociado al contraste.

Haced un diagrama de caja comparativo de los precios  en Alcudia  por periodo y coméntalo.

```{r}
# -------------------------------------------------------------------
# PREGUNTA 4
# Contraste de medias en Alcúdia: 2025-06-15 vs 2025-09-21
# Hipótesis: Media(Junio) < Media(Septiembre)
# -------------------------------------------------------------------

# 1. Filtrar los datos para Alcúdia y las dos fechas de interés
#    Aseguramos que la fecha sea de tipo Date para filtrar correctamente
fechas_interes <- as.Date(c("2025-06-15", "2025-09-21"))

datos_p4 <- listings0 %>%
  filter(neighbourhood_cleansed == "Alcúdia",
         date %in% fechas_interes) %>%
  # Seleccionamos variables útiles para limpiar un poco
  select(price, date, neighbourhood_cleansed)

# 2. Separar los precios en dos vectores para el t.test
precios_jun <- datos_p4 %>%
  filter(date == "2025-06-15") %>%
  pull(price)

precios_sep <- datos_p4 %>%
  filter(date == "2025-09-21") %>%
  pull(price)

# 3. Realizar el t-test (Welch Two Sample t-test)
#    alternative = "less" porque la hipótesis es que precios_jun < precios_sep
test_p4 <- t.test(x = precios_jun, 
                  y = precios_sep, 
                  alternative = "less", 
                  var.equal = FALSE)

# Mostrar resultados del test
test_p4

# -------------------------------------------------------------------
# DIAGRAMA DE CAJA (BOXPLOT) COMPARATIVO
# -------------------------------------------------------------------

ggplot(datos_p4, aes(x = factor(date), y = price, fill = factor(date))) +
  geom_boxplot(alpha = 0.7, outlier.colour = "red", outlier.size = 1) +
  scale_fill_manual(values = c("#3498db", "#e74c3c")) + # Colores personalizados
  labs(
    title = "Distribución de precios en Alcúdia por periodo",
    subtitle = "Comparativa: 15-Jun-2025 vs 21-Sep-2025",
    x = "Fecha de Scrapping",
    y = "Precio (€)",
    fill = "Fecha"
  ) +
  theme_minimal() +
  theme(legend.position = "none") # Ocultamos leyenda porque el eje X ya es claro
```


## Pregunta 5 (**1 punto**)

Comparar con un bopxlot de las valoraciones medias `review_scores_rating` para Alcudia, Palma, Calvià y
Pollença. Hacer el gráfico con ggplot2 y todo lujo de destalles.

```{r}
# -------------------------------------------------------------------
# PREGUNTA 5
# Comparación de review_scores_rating mediante Boxplot
# Municipios: Alcúdia, Palma de Mallorca, Calvià, Pollença
# -------------------------------------------------------------------

library(dplyr)
library(ggplot2)

# 1. Definir los municipios de interés
# Nota: Ajusta los nombres exactos según aparezcan en tus datos (tildes, etc.)
municipios_p5 <- c("Alcúdia", "Palma de Mallorca", "Calvià", "Pollença")

# 2. Preparar los datos
datos_p5 <- listings0 %>%
  filter(neighbourhood_cleansed %in% municipios_p5) %>%
  # Eliminamos filas sin puntuación para limpiar el gráfico
  filter(!is.na(review_scores_rating))

# 3. Generar el gráfico con "todo lujo de detalles"
ggplot(datos_p5, aes(x = neighbourhood_cleansed, y = review_scores_rating, fill = neighbourhood_cleansed)) +
  
  # Capa de Boxplot
  # outlier.alpha = 0.3 hace que los puntos atípicos sean semitransparentes para no saturar
  geom_boxplot(alpha = 0.7, outlier.colour = "red", outlier.alpha = 0.5, outlier.size = 1.5) +
  
  # Añadir un punto blanco/negro para indicar la MEDIA (el boxplot solo muestra la mediana)
  stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "white", color = "black") +
  
  # Colores personalizados (Paleta Brewer o manual)
  scale_fill_brewer(palette = "Set2") +
  
  # Etiquetas y Títulos completos
  labs(
    title = "Distribución de las valoraciones de los usuarios",
    subtitle = "Comparativa: Alcúdia, Calvià, Palma y Pollença",
    x = "Municipio",
    y = "Puntuación Media (Rating 0-5)",
    fill = "Municipio",
    caption = "Fuente: Inside Airbnb (listings0) | El rombo blanco indica la media"
  ) +
  
  # Tema estético limpio
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
    plot.subtitle = element_text(size = 11, hjust = 0.5, color = "gray40"),
    axis.text.x = element_text(face = "bold", size = 10),
    legend.position = "none" # Ocultamos leyenda porque el eje X ya identifica los grupos
  ) +
  
  # Ajustar escala Y si es necesario (el rating suele ser de 0 a 5 o de 0 a 100 según la versión)
  # En datasets recientes es sobre 5. Si tus datos son sobre 100, ajusta los límites.
  coord_cartesian(ylim = c(3, 5)) # Hacemos zoom en la parte superior donde están casi todos los datos
```


## Pregunta 6 (**1 punto**)

Calcular la proporción de apartamentos de la muestra "2025-09-21" con media de valoración `review_scores_rating` mayor que 4 en Alcudia y en Calvià son iguales contra que son distintas. Construid un intervalo de confianza para la diferencia de proporciones.

```{r}
# -------------------------------------------------------------------
# PREGUNTA 6
# Comparación de proporciones (Rating > 4): Alcúdia vs Calvià
# Fecha: 2025-09-21
# -------------------------------------------------------------------

# 1. Preparar los datos
datos_p6 <- listings0 %>%
  filter(date == as.Date("2025-09-21"),
         neighbourhood_cleansed %in% c("Alcúdia", "Calvià")) %>%
  filter(!is.na(review_scores_rating)) # Eliminamos los que no tienen puntuación

# 2. Calcular los conteos de "éxitos" y el total de observaciones por municipio
resumen_p6 <- datos_p6 %>%
  group_by(neighbourhood_cleansed) %>%
  summarise(
    exitos = sum(review_scores_rating > 4), # Conteo de ratings > 4
    total = n()                             # Total de apartamentos con rating
  )

# Mostramos la tabla resumen para verificar
resumen_p6

# 3. Extraer vectores para el prop.test
# Aseguramos el orden: Alcúdia primero, luego Calvià (orden alfabético por defecto)
# Ojo: prop.test pide vectores: x (éxitos) y n (totales)
x_exitos <- resumen_p6$exitos
n_totales <- resumen_p6$total

# 4. Realizar el test de proporciones (Two-sample test for equality of proportions)
test_p6 <- prop.test(x = x_exitos, n = n_totales, alternative = "two.sided")

# Mostrar resultados
test_p6
```


## Pregunta 7 (**1punto**)

Calcular la proporción de apartamentos de los periodos 2025-06-15 y  2025-09-21  con media de valoración `review_scores_rating` mayor que 4 en Palma  y en Pollença son iguales contra que son distintas.

```{r}
# -------------------------------------------------------------------
# PREGUNTA 7
# Comparación de proporciones (Rating > 4): Palma vs Pollença
# Periodos combinados: 2025-06-15 y 2025-09-21
# -------------------------------------------------------------------

# 1. Filtrar datos: Fechas y Municipios específicos
fechas_p7 <- as.Date(c("2025-06-15", "2025-09-21"))
municipios_p7 <- c("Palma de Mallorca", "Pollença")

datos_p7 <- listings0 %>%
  filter(date %in% fechas_p7,
         neighbourhood_cleansed %in% municipios_p7) %>%
  filter(!is.na(review_scores_rating)) # Eliminar NAs en la valoración

# 2. Calcular éxitos y totales por municipio
# Al agrupar por municipio, R sumará los casos de ambas fechas automáticamente
resumen_p7 <- datos_p7 %>%
  group_by(neighbourhood_cleansed) %>%
  summarise(
    exitos = sum(review_scores_rating > 4),
    total = n()
  )

# Ver tabla resumen
resumen_p7

# 3. Preparar vectores para el test
# Nota: Verifica el orden alfabético en 'resumen_p7' para saber cuál es prop 1 y prop 2.
# Generalmente: 1 = Palma de Mallorca, 2 = Pollença
x_exitos_p7 <- resumen_p7$exitos
n_totales_p7 <- resumen_p7$total

# 4. Realizar el test de proporciones (Two-sample test for equality of proportions)
test_p7 <- prop.test(x = x_exitos_p7, n = n_totales_p7, alternative = "two.sided")

# Mostrar resultados
test_p7
```


## Pregunta 8 (**1punto**)

Agrupa las variables `review_scores_rating` y `review_scores_location` de `listings0` en 5 categorías cada una y construid una tabla de contingencia con las dos variables agrupadas. Agrupar de forma que no cruces de categorías vacías. Contratar si esta varibles son independientes con  un test $\chi^2$. 

Buscan información sobre el coeficiente de contingencia de Carl Pearson, cacularlo desde  la salida de chisq.test interpretarlo  en esta caso


```{r}
table(cut(listings0$review_scores_rating,5),
      cut(listings0$review_scores_location,5))
```

```{r}
# -------------------------------------------------------------------
# PREGUNTA 8
# Test de Independencia Chi-cuadrado y Coeficiente de Contingencia
# Variables: review_scores_rating y review_scores_location
# -------------------------------------------------------------------

# 1. Preparar los datos (eliminar NAs)
datos_p8 <- listings0 %>%
  select(review_scores_rating, review_scores_location) %>%
  na.omit()

# 2. Agrupar en 5 categorías usando QUANTILES para evitar celdas vacías
#    La función quantile calcula los puntos de corte para tener grupos equilibrados (0%, 20%, 40%, 60%, 80%, 100%)
#    Nota: Si hay muchos valores repetidos (ej. muchos 5.0), 'cut' puede dar error por "breaks not unique".
#    En ese caso, ajustamos ligeramente o reducimos grupos, pero intentamos primero con quintiles.

# Calculamos los cortes
breaks_rating <- unique(quantile(datos_p8$review_scores_rating, probs = seq(0, 1, 0.2)))
breaks_location <- unique(quantile(datos_p8$review_scores_location, probs = seq(0, 1, 0.2)))

# Creamos los factores
# include.lowest = TRUE asegura que el valor mínimo entre en el primer intervalo
datos_p8$cat_rating <- cut(datos_p8$review_scores_rating, breaks = breaks_rating, include.lowest = TRUE)
datos_p8$cat_location <- cut(datos_p8$review_scores_location, breaks = breaks_location, include.lowest = TRUE)

# 3. Construir la Tabla de Contingencia
tabla_contingencia <- table(datos_p8$cat_rating, datos_p8$cat_location)

print("Tabla de Contingencia:")
print(tabla_contingencia)

# 4. Realizar el Test Chi-cuadrado
test_chi <- chisq.test(tabla_contingencia)

print(test_chi)

# 5. Calcular el Coeficiente de Contingencia de Pearson
#    Fórmula: C = raiz( Chi^2 / (N + Chi^2) )
chi_squared_stat <- test_chi$statistic
N <- sum(tabla_contingencia) # Tamaño total de la muestra

coef_contingencia <- sqrt(chi_squared_stat / (N + chi_squared_stat))

# Mostramos el resultado
cat("\nCoeficiente de Contingencia de Pearson (C):", round(coef_contingencia, 4), "\n")

# (Opcional) Calcular el máximo posible para C para normalizarlo (C_max)
# C nunca llega a 1. Su máximo depende del número de filas/columnas (k). C_max = raiz((k-1)/k)
k <- min(dim(tabla_contingencia))
c_max <- sqrt((k - 1) / k)
cat("Coeficiente normalizado (C / C_max):", round(coef_contingencia / c_max, 4), "\n")
```


## Pregunta 9 (**3 puntos**)

Construye un data set con las variables 
review_scores_rating, review_scores_cleanliness, review_scores_location, review_scores_value de listings0 y  el municipio/zona `neighbourhood_cleansed`

Calcula la matriz de correlaciones entre estas variables y haz un gráfico de pares  de variables que muestre las correlaciones ([ggpairs](https://r-charts.com/correlation/ggpairs/)) con la librería GGally. Comenta los resultados.

Haz un `matrixplot` de las correlaciones con la librería `corrplot`. Comenta los resultados.

## Pregunta 10 (**2 puntos**)

La [Zipf's law es una ley empírica](https://en.wikipedia.org/wiki/Zipf%27s_law#Word_frequencies_in_natural_languages) que dice que la frecuencia de las palabras en un texto es inversamente proporcional a su rango. Decidid si la ley se ajusta a los datos de la longitud de los comentarios de los apartamentos de la muestra "2025-09-21" Mallorca, haced lo mismo para description de `listings0`. Para ello, haced un análisis de regresión lineal de la frecuencia de las longitudes de los comentarios/descripciones de los apartamentos de Mallorca y el rango de las longitudes de los comentarios. Justificad la respuesta, estadísticamente y gráficamente.

Como ayuda estudiar el siguiente código, utilizadlo y comentadlo.

```{r}
library(stringr)
# para las reseñas
head(reviews)
length_rewiews=stringr::str_count(reviews$comments,"\\w+")
barplot(table(length_rewiews))

#para las descripciones
length_description=stringr::str_count(listings0$description,"\\w+")
barplot(table(length_description))
```

Y ahora se calculan los rango os lo dejo para reviews par desctption lo haceís vosotros

```{r}

aux=table(length_rewiews)
head(aux)
head(names(aux))
tbl=tibble( L=as.numeric(names(aux)),Freq=as.numeric(aux),
            Rank=rank(L),Log_Freq=log(Freq),Log_Rank=log(Rank))
str(tbl)
```

```{r}
tbl2=tbl %>% filter(Rank>10) %>% filter(Rank<1000)
sol1=lm(tbl2$Freq~tbl2$Rank)
summary(sol1)

sol2=lm(tbl2$Freq~tbl2$Log_Rank)
summary(sol2)

sol3=lm(tbl2$Log_Freq~tbl2$Log_Rank)
summary(sol3)
```


